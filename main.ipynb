{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhupesh-varma/PhysiSolve/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3OlwGoEWzrh"
      },
      "source": [
        "## Step - 1\n",
        "### spplitting the dataset into training, testing and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bCr_L7WXflr",
        "outputId": "8ec94b79-0d4a-40de-91ca-3754e433f92d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJwjC33HWzrj",
        "outputId": "f150645e-28b7-478b-dd64-81c6e468c2e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original subject distribution: Counter({'Electrostatics and Current Electricity': 76, 'Mechanics': 60, 'Kinematics': 55, 'Electromagnetism': 45, 'Thermodynamics': 44, 'Optics': 38, 'Atomic and Modern Physics': 30, 'Electronic Devices': 29, 'Periodic Motion': 13, 'Waves and Oscillations': 10})\n",
            "\n",
            "Dataset split into 280 training, 60 testing, and 60 evaluation samples.\n",
            "\n",
            "Subject distribution in each split:\n",
            "Train: Counter({'Electrostatics and Current Electricity': 53, 'Mechanics': 42, 'Kinematics': 39, 'Thermodynamics': 31, 'Electromagnetism': 31, 'Optics': 27, 'Atomic and Modern Physics': 21, 'Electronic Devices': 20, 'Periodic Motion': 9, 'Waves and Oscillations': 7})\n",
            "Test: Counter({'Electrostatics and Current Electricity': 11, 'Mechanics': 9, 'Kinematics': 8, 'Electromagnetism': 7, 'Thermodynamics': 6, 'Optics': 5, 'Atomic and Modern Physics': 5, 'Electronic Devices': 5, 'Periodic Motion': 2, 'Waves and Oscillations': 2})\n",
            "Eval: Counter({'Electrostatics and Current Electricity': 12, 'Mechanics': 9, 'Kinematics': 8, 'Thermodynamics': 7, 'Electromagnetism': 7, 'Optics': 6, 'Electronic Devices': 4, 'Atomic and Modern Physics': 4, 'Periodic Motion': 2, 'Waves and Oscillations': 1})\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Load the dataset\n",
        "with open(r\"/content/drive/MyDrive/dataset/high_school_physics.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the 'subject' field for stratification\n",
        "subjects = [item[\"subject\"] for item in data]\n",
        "\n",
        "# Verify initial distribution\n",
        "print(\"Original subject distribution:\", Counter(subjects))\n",
        "\n",
        "# First split: 70% train, 30% temp (test + eval)\n",
        "train_data, temp_data = train_test_split(\n",
        "    data,\n",
        "    train_size=0.7,\n",
        "    stratify=subjects,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Second split: Split the 30% temp into 15% test and 15% eval (50/50 of temp)\n",
        "test_data, eval_data = train_test_split(\n",
        "    temp_data,\n",
        "    test_size=0.5,  # 50% of 30% = 15% of original\n",
        "    stratify=[item[\"subject\"] for item in temp_data],\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Save train, test, and evaluation sets\n",
        "with open(r\"/content/drive/MyDrive/dataset/train.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(train_data, f, indent=4)\n",
        "with open(r\"/content/drive/MyDrive/dataset/test.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(test_data, f, indent=4)\n",
        "with open(r\"/content/drive/MyDrive/dataset/eval.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(eval_data, f, indent=4)\n",
        "\n",
        "# Print split sizes and subject distribution\n",
        "print(f\"\\nDataset split into {len(train_data)} training, {len(test_data)} testing, and {len(eval_data)} evaluation samples.\")\n",
        "print(\"\\nSubject distribution in each split:\")\n",
        "print(\"Train:\", Counter([item[\"subject\"] for item in train_data]))\n",
        "print(\"Test:\", Counter([item[\"subject\"] for item in test_data]))\n",
        "print(\"Eval:\", Counter([item[\"subject\"] for item in eval_data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of the Output\n",
        "#### Original Distribution\n",
        "- **Total samples**: 400\n",
        "- **Subjects**:\n",
        "  - Electrostatics and Current Electricity: 76\n",
        "  - Mechanics: 60\n",
        "  - Kinematics: 55\n",
        "  - Electromagnetism: 45\n",
        "  - Thermodynamics: 44\n",
        "  - Optics: 38\n",
        "  - Atomic and Modern Physics: 30\n",
        "  - Electronic Devices: 29\n",
        "  - Periodic Motion: 13\n",
        "  - Waves and Oscillations: 10\n",
        "\n",
        "#### Split Results\n",
        "- **Train**: 280 samples (70%)\n",
        "- **Test**: 60 samples (15%)\n",
        "- **Eval**: 60 samples (15%)\n",
        "\n",
        "#### Subject Distribution Across Splits\n",
        "| Subject                          | Original | Train (70%) | Test (15%) | Eval (15%) |\n",
        "|----------------------------------|----------|-------------|------------|------------|\n",
        "| Electrostatics and Current Elec. | 76       | 53 (53.2)   | 11 (11.4)  | 12 (11.4)  |\n",
        "| Mechanics                        | 60       | 42 (42)     | 9 (9)      | 9 (9)      |\n",
        "| Kinematics                       | 55       | 39 (38.5)   | 8 (8.25)   | 8 (8.25)   |\n",
        "| Electromagnetism                 | 45       | 31 (31.5)   | 7 (6.75)   | 7 (6.75)   |\n",
        "| Thermodynamics                   | 44       | 31 (30.8)   | 6 (6.6)    | 7 (6.6)    |\n",
        "| Optics                           | 38       | 27 (26.6)   | 5 (5.7)    | 6 (5.7)    |\n",
        "| Atomic and Modern Physics        | 30       | 21 (21)     | 5 (4.5)    | 4 (4.5)    |\n",
        "| Electronic Devices               | 29       | 20 (20.3)   | 5 (4.35)   | 4 (4.35)   |\n",
        "| Periodic Motion                  | 13       | 9 (9.1)     | 2 (1.95)   | 2 (1.95)   |\n",
        "| Waves and Oscillations           | 10       | 7 (7)       | 2 (1.5)    | 1 (1.5)    |\n"
      ],
      "metadata": {
        "id": "UKGUfjMv7qpa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t15fKpYVWzrm"
      },
      "source": [
        "### Few-Shot Evaluation of Flan-T5 from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3jf9z-URWzrn",
        "outputId": "97fbfdfd-1f82-4f7a-d4a9-9cac467f494b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "f40f11ac1f704eeb8cfcf713a896ddd2",
            "007c2a3531584a95978e2782879441f5",
            "c449ce44d9ac4c46b8eb170b6eff98a9",
            "c3257bc1de214b639110b937ff92ed5a",
            "e0d53f050def4831ab9c0e9b1544c77d",
            "de6d5d2436de4fe490539410f881c255",
            "8fb13918e01d49e2939bd8cf8eba62c0",
            "b0f3f75a9d4e493eb579dd23d084b3f4",
            "6bc52e05c81743cbbee715cb06cb23b9",
            "c4547ecd632640409470031bb982b4a3",
            "20643329d6f1492693bec6738431adff"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f40f11ac1f704eeb8cfcf713a896ddd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"microsoft/phi-3-mini-4k-instruct\",\n",
        "    device_map = \"auto\",\n",
        "    torch_dtype=\"auto\"\n",
        ")\n",
        "\n",
        "def evaluate_model(model, dataset):\n",
        "    correct = 0\n",
        "    total = len(dataset)\n",
        "\n",
        "    for item in dataset:\n",
        "        question = item[\"question\"]\n",
        "        idx = ord(item[\"answer\"])-ord(\"A\")\n",
        "        correct_answer = item[\"choices\"][idx]\n",
        "\n",
        "        prompt = f\"Give me the final answer without any explaination, just the couple of words with units that directly show the answer for the Question: {question} with Choices: {', '.join(item['choices'])} Answer:\"\n",
        "        prediction = model(prompt, max_length=100, truncation=True)[0][\"generated_text\"]\n",
        "\n",
        "        predicted_answer = prediction.split(\"Answer:\")[-1].strip()\n",
        "        if correct_answer.lower() in prediction.lower():\n",
        "          correct += 1\n",
        "\n",
        "    accuracy = (correct / total) * 100\n",
        "    return accuracy\n",
        "\n",
        "zero_shot_accuracy = evaluate_model(qa_pipeline, test_data)\n",
        "print(f\"Zero-Shot Accuracy: {zero_shot_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuning Flan-T5 using LoRA"
      ],
      "metadata": {
        "id": "Eef1iSSngxg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Disable W&B logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Load Phi-3 model and tokenizer\n",
        "model_name = \"microsoft/phi-3-mini-128k-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32)  # Use float32 for CPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Create custom dataset\n",
        "class PhysicsDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        prompt = f\"Question: {item['question']}\\nChoices: {', '.join(item['choices'])}\\nAnswer:\"\n",
        "        idx = ord(item[\"answer\"][0]) - ord(\"A\")\n",
        "        target = item[\"choices\"][idx]\n",
        "\n",
        "        # For causal models, concatenate input and target as one string\n",
        "        full_text = prompt + \" \" + target\n",
        "        encoding = self.tokenizer(full_text, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze()\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
        "\n",
        "        # Labels are the same as input_ids, but mask out padding tokens\n",
        "        labels = input_ids.clone()\n",
        "        labels[attention_mask == 0] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "        }\n",
        "\n",
        "# Load data\n",
        "train_file_path = \"/content/drive/MyDrive/dataset/train.json\"\n",
        "eval_file_path = \"/content/drive/MyDrive/dataset/eval.json\"\n",
        "\n",
        "with open(train_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(eval_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    eval_data = json.load(f)\n",
        "\n",
        "train_dataset = PhysicsDataset(train_data, tokenizer)\n",
        "eval_dataset = PhysicsDataset(eval_data, tokenizer)\n",
        "\n",
        "# Output directories\n",
        "model_save_dir = \"/content/drive/MyDrive/dataset/trained_model_phi3\"\n",
        "results_dir = \"/content/drive/MyDrive/dataset/results_phi3\"\n",
        "os.makedirs(model_save_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=results_dir,\n",
        "    per_device_train_batch_size=2,  # Smaller batch size for Phi-3\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    run_name=f\"phi3-mini-{time.strftime('%Y%m%d-%H%M%S')}\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(model_save_dir)\n",
        "tokenizer.save_pretrained(model_save_dir)\n",
        "print(f\"Phi-3 model and tokenizer saved to {model_save_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "79e2ea9f1ecd438ea1f5f9b9bedb2792",
            "1552cea0fbab4430a192f3f5423f929d",
            "bc5b3160aa734ae5a2f2d10adc706dd6",
            "437d0929d6ad40fb8edae5646b6562e9",
            "e1b3f2ece4034941935cbb285b11729b",
            "64d7a5c87d984897a971868741a79867",
            "e86857b9801948689a3dba72a956a8be",
            "2e5560e74dfe4b579dab1d019aa40e85",
            "8444f5fcb3974ea1944e9738a5a7d71b",
            "f4e4870cf6fa445d8565811541cf173e",
            "b749790a7f8245dfb201e4cb154589d7"
          ]
        },
        "id": "f9mgCN8qg85c",
        "outputId": "5bbef959-b6fe-4d0c-abe6-1d0200c3e09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79e2ea9f1ecd438ea1f5f9b9bedb2792"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCuxI6ReWzrn"
      },
      "source": [
        "### Testing the trained model on test.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "model_save_dir = \"/content/drive/MyDrive/dataset/trained_model\"\n",
        "test_file_path = \"/content/drive/MyDrive/dataset/test.json\"  # Adjust if your test file has a different name\n",
        "\n",
        "# First, let's check if the model files exist\n",
        "print(\"Checking model directory contents:\")\n",
        "for root, dirs, files in os.walk(model_save_dir):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n",
        "\n",
        "# Load the model and tokenizer\n",
        "try:\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_save_dir)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_save_dir)\n",
        "    print(\"Model and tokenizer loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    # If model loading fails, load the original pretrained model\n",
        "    print(\"Loading the base model instead...\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\", legacy=False)\n",
        "\n",
        "# Load test data\n",
        "with open(test_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(test_data)} test examples\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Testing function\n",
        "def evaluate_model(model, tokenizer, test_data, device, correct, total):\n",
        "\n",
        "    for item in tqdm(test_data):\n",
        "        prompt = f\"Question: {item['question']} Choices: {', '.join(item['choices'])} Answer:\"\n",
        "        correct_idx = ord(item[\"answer\"][0]) - ord(\"A\")\n",
        "        correct_answer = item[\"choices\"][correct_idx]\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=128).input_ids.to(device)\n",
        "\n",
        "        # Generate output\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                max_length=128,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        # Decode output\n",
        "        predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Simple string match for evaluation\n",
        "        if predicted_text.strip() == correct_answer.strip():\n",
        "            correct += 1\n",
        "        else:\n",
        "            # Print some examples of wrong predictions for debugging\n",
        "            if total < 5:  # Limit to just a few examples\n",
        "                print(f\"\\nQuestion: {item['question']}\")\n",
        "                print(f\"Choices: {', '.join(item['choices'])}\")\n",
        "                print(f\"Correct Answer: {correct_answer}\")\n",
        "                print(f\"Predicted: {predicted_text}\")\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Evaluating model on test set...\")\n",
        "correct = 0\n",
        "total = 0\n",
        "accuracy = evaluate_model(model, tokenizer, test_data, device, correct, total)\n",
        "print(f\"Test Accuracy: {accuracy:.4f} ({correct}/{total})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOcarEpxa5nP",
        "outputId": "fdf7d64c-5027-4c82-b99c-85040f66527e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking model directory contents:\n",
            "Error loading model: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /content/drive/MyDrive/dataset/trained_model.\n",
            "Loading the base model instead...\n",
            "Loaded 60 test examples\n",
            "Evaluating model on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/60 [00:05<05:38,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: A 10 Ω resistor is connected across a 15 V battery. What is the current flowing through the resistor?\n",
            "Choices: 0.5 A, 1 A, 1.5 A, 2 A\n",
            "Correct Answer: 1.5 A\n",
            "Predicted: 2 A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/60 [00:11<05:44,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: A force of 100 N is applied to a 50 kg object. What is the acceleration of the object?\n",
            "Choices: 1 m/s², 2 m/s², 3 m/s², 4 m/s²\n",
            "Correct Answer: 2 m/s²\n",
            "Predicted: 4 m/s2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 3/60 [00:14<04:02,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: What is the equivalent resistance of two 10Ω resistors in parallel?\n",
            "Choices: 5Ω, 10Ω, 20Ω, 0Ω\n",
            "Correct Answer: 5Ω\n",
            "Predicted: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 4/60 [00:18<03:54,  4.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: A force of 80 N is applied to a 8 kg block. What is the acceleration of the block?\n",
            "Choices: 5 m/s², 10 m/s², 15 m/s², 20 m/s²\n",
            "Correct Answer: 10 m/s²\n",
            "Predicted: 20 m/s2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/60 [00:21<03:35,  3.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Two resistors of 15Ω and 5Ω are connected in parallel. What is the equivalent resistance?\n",
            "Choices: 1Ω, 2Ω, 3.75Ω, 5Ω\n",
            "Correct Answer: 3.75Ω\n",
            "Predicted: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [03:16<00:00,  3.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.2667 (0/0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from torch.utils.data import Dataset\n",
        "import pickle\n",
        "\n",
        "# Load trained model\n",
        "model_path = \"/content/drive/MyDrive/dataset/trained_model.pkl\"\n",
        "with open(model_path, \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Load tokenizer\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)\n",
        "\n",
        "# Load test dataset\n",
        "test_file_path = \"/content/drive/MyDrive/dataset/test.json\"\n",
        "with open(test_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# Define test dataset class\n",
        "class PhysicsDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        prompt = f\"Question: {item['question']} Choices: {', '.join(item['choices'])} Answer:\"\n",
        "        idx = ord(item[\"answer\"][0])-ord(\"A\")  # Convert letter to index\n",
        "        target = item[\"choices\"][idx]\n",
        "\n",
        "        encodings = self.tokenizer(prompt, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
        "        target_encodings = self.tokenizer(target, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encodings[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encodings[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": target_encodings[\"input_ids\"].squeeze(),\n",
        "            \"correct_answer\": target\n",
        "        }\n",
        "\n",
        "# Prepare test dataset\n",
        "test_dataset = PhysicsDataset(test_data, tokenizer)\n",
        "\n",
        "# Function to evaluate accuracy\n",
        "def evaluate_accuracy(model, dataset, tokenizer):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for item in dataset:\n",
        "        input_ids = item[\"input_ids\"].unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        attention_mask = item[\"attention_mask\"].unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Generate prediction\n",
        "        with torch.no_grad():\n",
        "            output = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n",
        "\n",
        "        # Decode predicted and actual answer\n",
        "        predicted_answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        correct_answer = item[\"correct_answer\"]\n",
        "\n",
        "        # Compare answers\n",
        "        if predicted_answer.strip().lower() == correct_answer.strip().lower():\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "    accuracy = (correct / total) * 100\n",
        "    return accuracy\n",
        "\n",
        "# Run evaluation\n",
        "accuracy = evaluate_accuracy(model, test_dataset, tokenizer)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "staNM7elaDE6",
        "outputId": "bdd95702-b292-4535-d487-4f65216d7bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "Ran out of input",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-57372ddb6807>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/dataset/trained_model.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f40f11ac1f704eeb8cfcf713a896ddd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_007c2a3531584a95978e2782879441f5",
              "IPY_MODEL_c449ce44d9ac4c46b8eb170b6eff98a9",
              "IPY_MODEL_c3257bc1de214b639110b937ff92ed5a"
            ],
            "layout": "IPY_MODEL_e0d53f050def4831ab9c0e9b1544c77d"
          }
        },
        "007c2a3531584a95978e2782879441f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de6d5d2436de4fe490539410f881c255",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb13918e01d49e2939bd8cf8eba62c0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c449ce44d9ac4c46b8eb170b6eff98a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f3f75a9d4e493eb579dd23d084b3f4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bc52e05c81743cbbee715cb06cb23b9",
            "value": 2
          }
        },
        "c3257bc1de214b639110b937ff92ed5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4547ecd632640409470031bb982b4a3",
            "placeholder": "​",
            "style": "IPY_MODEL_20643329d6f1492693bec6738431adff",
            "value": " 2/2 [00:00&lt;00:00,  5.66it/s]"
          }
        },
        "e0d53f050def4831ab9c0e9b1544c77d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de6d5d2436de4fe490539410f881c255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb13918e01d49e2939bd8cf8eba62c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0f3f75a9d4e493eb579dd23d084b3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc52e05c81743cbbee715cb06cb23b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4547ecd632640409470031bb982b4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20643329d6f1492693bec6738431adff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e2ea9f1ecd438ea1f5f9b9bedb2792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1552cea0fbab4430a192f3f5423f929d",
              "IPY_MODEL_bc5b3160aa734ae5a2f2d10adc706dd6",
              "IPY_MODEL_437d0929d6ad40fb8edae5646b6562e9"
            ],
            "layout": "IPY_MODEL_e1b3f2ece4034941935cbb285b11729b"
          }
        },
        "1552cea0fbab4430a192f3f5423f929d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d7a5c87d984897a971868741a79867",
            "placeholder": "​",
            "style": "IPY_MODEL_e86857b9801948689a3dba72a956a8be",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "bc5b3160aa734ae5a2f2d10adc706dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5560e74dfe4b579dab1d019aa40e85",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8444f5fcb3974ea1944e9738a5a7d71b",
            "value": 1
          }
        },
        "437d0929d6ad40fb8edae5646b6562e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e4870cf6fa445d8565811541cf173e",
            "placeholder": "​",
            "style": "IPY_MODEL_b749790a7f8245dfb201e4cb154589d7",
            "value": " 1/2 [00:30&lt;00:30, 30.75s/it]"
          }
        },
        "e1b3f2ece4034941935cbb285b11729b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d7a5c87d984897a971868741a79867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86857b9801948689a3dba72a956a8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e5560e74dfe4b579dab1d019aa40e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8444f5fcb3974ea1944e9738a5a7d71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4e4870cf6fa445d8565811541cf173e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b749790a7f8245dfb201e4cb154589d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}